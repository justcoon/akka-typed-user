include classpath("discovery-local.conf")
include classpath("kamon.conf")

akka {
  actor {
    provider = cluster
    //    provider = akka.cluster.ClusterActorRefProvider

    allow-java-serialization = off

    serializers {
      kryo = "io.altoo.akka.serialization.kryo.KryoSerializer"
      proto = "akka.remote.serialization.ProtobufSerializer"
    }

    serialization-bindings {
      "scalapb.GeneratedMessage" = proto
      "java.io.Serializable" = kryo
    }
  }

  //akka 2.6
  remote {
    enabled-transports = ["akka.remote.artery.canonical"]
    artery.canonical {
      hostname = "127.0.0.1"
      //      port = ${REMOTE_PORT}
      port = 2551
    }
  }

  // The following settings are for super fast automatic removal of unreachable nodes and not suitable for production!
  cluster {
    //    auto-down-unreachable-after = 0 seconds
    //    unreachable-nodes-reaper-interval = 250 milliseconds
    //
    //    failure-detector {
    //      acceptable-heartbeat-pause = 1 second
    //      hearbeat-interval = 250 milliseconds
    //      threshold = 4.0
    //    }
    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"

    seed-nodes = [
      "akka://user@127.0.0.1:2551",
      "akka://user@127.0.0.1:2552",
      "akka://user@127.0.0.1:2553"
    ]

    min-nr-of-members = 1
    auto-down-unreachable-after = 30s
  }

  //  extensions = [
  //    akka.persistence.Persistence,
  //    de.heikoseeberger.constructr.ConstructrExtension
  //  ]

  extensions = [
    akka.persistence.Persistence
  ]

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "INFO"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
}

akka.http {
  server {
    preview.enable-http2 = on
    backlog = 200
  }
}

akka.management {
  health-checks {
    readiness-checks {
      example-ready = "com.jc.user.UserHealthCheck"
    }
  }
}


akka.persistence {

  journal.plugin = "akka.persistence.cassandra.journal"
  snapshot-store.plugin = "akka.persistence.cassandra.snapshot"

  cassandra {
    journal {
      keyspace = "c_user_journal"
      keyspace-autocreate = on
      tables-autocreate = on
      write-static-column-compat = off
    }
    snapshot {
      keyspace = "c_user_snapshot"
      keyspace-autocreate = on
      tables-autocreate = on
    }
    query {
      refresh-interval = 20ms
    }
    events-by-tag {
      first-time-bucket = "20200120T00:00"
    }
  }
}

akka.projection {
  cassandra {
    offset-store {
      keyspace = "c_user_projection"
      table = "offset_store"
    }
  }
}


alpakka.cassandra {
  # Configure Akka Discovery by setting a service name
  service-discovery {
    name = "cassandra"
    name = ${?CASSANDRA_SERVICE}
  }
}


akka.kafka.producer {
  # Configure Akka Discovery by setting a service name
  service-name = "kafka"
  service-name = ${?KAFKA_SERVICE}
}

akka.kafka.consumer {
  # Configure Akka Discovery by setting a service name
  service-name = "kafka"
  service-name = ${?KAFKA_SERVICE}
}

elasticsearch {
  addresses = ["localhost:9200"]
  //  addresses.0 = ${?ELASTICSEARCH_URL}
  user-index-name = "c_user"
  department-index-name = "c_department"
}

kafka {
  user-topic = "c-user"
  department-topic = "c-department"
}

jwt {
  secret = "mySecret"
  expiration = 604800000 // in milliseconds
}

rest-api {
  address = 0.0.0.0
  port = 8000
  repository-timeout = 250 milliseconds
}


grpc-api {
  address = 0.0.0.0
  port = 8010
  repository-timeout = 250 milliseconds
}
